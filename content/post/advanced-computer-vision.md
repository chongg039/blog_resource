---
title: "高级计算机视觉知识点总结"
date: 2019-05-12T19:09:40+08:00
Description: ""
Tags: [CV]
Categories: [CV]

---

我自己在做的方向是 NLP 相关，但这学期也选修了高级计算机视觉这门课程，其中很大一部分内容都是传统的视觉算法，和现在被人熟知的机器学习相关的 CV 领域还是有很大区别。由于这门课程也是学院第一次开课，所以也没有办法去做针对性的复习，故在此作以下学习记录，写下自己的理解，希望将来能温故而知新。

## 特征提取算法

涉及到的特征提取算法主要有 Harris 角点检测算法、Canny 边缘检测算法和 SIFT 尺度不变特征变换算法。

### Harris Corner Detection

首先要理解角点和其具有的特征：

1. 角点是轮廓之间的交点
2. 针对同一场景，即使视角发生变化，角点通常仍具备稳定的特征
3. 角点附近的区域的像素点的梯度无论是方向还是幅值都会有较大的变化

针对以上角点的特征，Harris 算法的基本思想是：使用一个固定大小的窗口在图向上进行**任意方向**上的滑动，比较滑动前后的窗口中像素灰度变化的程度。若沿任意方向的滑动**都**有较大的灰度变化，则认为该窗口中存在角点。

现在要做的就是设计一个函数，来衡量滑动前后的灰度值变化，并设置一个阈值，当灰度变化超过这个阈值认为存在角点。

这个函数可以作如下表示：

$$
E(u, v) = \sum_{x, y} w(x, y) [I(x+u, y+v) - I(x, y)]^2
$$

其中 $w(x, y)$ 是窗口函数（矩阵），常用的有 (0, 1) 函数和高斯函数，$I(x, y)$ 表示灰度强度值。下面要用到泰勒展开式处理这个函数。

二维泰勒展开式为：

$$
f(x+u, y+v) = f(x, y) + uf_x(x, y) + vf_y(x, y) + ...
$$

抛开 $w(x, y)$ ，先处理 $\sum[...]^2$ 这部分：

$$
\begin{align}
\sum[I(x+u, y+v) - I(x, y)]^2 & = \sum[I(x, y) + uI_x + vI_y - I(x, y)]^2 
\\\\ & =\sum(u^2I_x^2 + 2uvI_xI_y + v^2I_y^2) 
\\\\ & =\sum\bigg(
\begin{bmatrix}
u & v
\end{bmatrix}
\begin{bmatrix}
I_x^2 & I_xI_y \\\\\\
I_xI_y & I_y^2
\end{bmatrix}
\begin{bmatrix}
u\\\\\\
v
\end{bmatrix}
\bigg) 
\\\\ & =\begin{bmatrix}
u & v
\end{bmatrix}
\sum\begin{bmatrix}
I_x^2 & I_xI_y\\\\\\
I_xI_y & I_y^2
\end{bmatrix}
\begin{bmatrix}
u\\\\\\
v
\end{bmatrix}
\end{align}
$$

所以可以简化为：

$$
E(u, v) =
\begin{bmatrix}
u & v
\end{bmatrix}
M\begin{bmatrix}
u\\\\\\
v
\end{bmatrix} \quad
其中 \quad M =\sum_{x, y}w(x, y)
\begin{bmatrix}
I_x^2 & I_xI_y\\\\\\
I_xI_y & I_y^2
\end{bmatrix}
$$

但是 Harris 不是直接使用 $E(u, v)$ 的值判断角点存在与否，而是使用了一个技巧，通过对窗口中每个像素 x 方向和 y 方向上的梯度进行统计分析，每个像素的梯度坐标可以表示为 $(I_x, I_y)$ 。下面先来看一张图：

![图源：David G.Lowe](https://live.staticflickr.com/65535/32893623777_8b57140cea_o.jpg)

图中的 $\lambda_1, \lambda_2$ 是矩阵 M 的特征值，将 $\lambda_1$ 放在 x 轴方向，$\lambda_2$ 放在 y 轴方向，这个正方形区域中根据统计分为四个部分：

1. 左下方的 flat 区域：这个区域中 $\lambda_1$ 和 $\lambda_2$ 都非常小而且接近，落在此区域中的像素点在图像中多坐落在灰度变化不剧烈的平坦区域。
2. 右下方的 edge 区域：这个区域中 $\lambda_1$ 要远大于 $\lambda_2$ ，说明图像在 x 轴方向变化剧烈，y 轴方向变化不明显。说明图像中存在垂直方向的边缘。
3. 左上方的 edge 区域：这个区域中 $\lambda_2$ 要远大于 $\lambda_1$ ，说明图像在 y 轴方向变化剧烈，x 轴方向变化不明显。说明图像中存在水平方向的边缘。
4. 右上方的 Corner 区域：这个区域中 $\lambda_1$ 和 $\lambda_2$ 都非常大而且接近，说明落在该区域中的像素点在 x 轴方向和 y 轴方向变化都较为剧烈，在图像中即表示为角点。

所以我们根据 $\lambda_1$ 和 $\lambda_2$ 就可以度量角点的存在性，而不需要通过直接计算 $E(u, v)$ 了。即通过定义一个响应函数 R 来度量角点的存在性：
$$
R = min(\lambda_1, \lambda_2)
$$
R 的含义是：若两个特征值中较小的值都很大，说明存在角点。

但直接计算 M 的特征值比较耗时，对矩阵 M ，可以得到：
$$
\begin{align}
det|M| & = \lambda_1\lambda_2 \\\\
trace(M) & = \lambda_1 + \lambda_2
\end{align}
$$
这样 R 就可以重新定义为：
$$
R = det|M| - k * trace(M) = \lambda_1\lambda_2 - k(\lambda_1 + \lambda_2)^2 \quad 0.04 < k < 0.06
$$
根据矩阵 M ，R 也可以这样写：
$$
\begin{align}
R & = det|M| - k * trace(M)
\\\\& = g(I_x^2)g(I_y^2) - [g(I_xI_y)]^2 - k[g(I_x^2) + g(I_y^2)]^2 
\\\\& 将\sum w(x, y) 简记为 g() ，可以认为 g 是一个高斯滤波器
\end{align}
$$


下面要做的就是对 R 设置一个阈值判断角点的存在性，再使用非极大值抑制精确角点区域的范围就可以了。这就是 Harris 角点检测的基本思路，总结一下是：

1. 计算窗口在 x 和 y 方向的梯度 $I_x$ 和 $I_y$ 
2. 计算梯度间的乘积得到 $I_x^2, I_y^2, I_x I_y$
3. 使用高斯滤波器 g 计算得到 $g(I_x^2), g(I_y^2), g(I_x I_y)$
4. 计算 R 的值
5. 设置阈值判断角点的存在性
6. 使用非极大值抑制精确区域

这个算法可以适应图片的旋转，但对缩放不能很好的解决，因为缩小图片会使角点变成一个点，放大会使角点变成平滑的边缘。Harris 方法稍加改动也可以判断边缘的存在性。

### Canny Edge Detection

使用 Canny 算子进行边缘检测的步骤如下：

1. 首先使用高斯滤波平滑和降噪：使用一个 $g_\sigma(m, n)$ 去平滑图片区域 $f(m, n)$ ，即用一个高斯矩阵乘以每个像素点及其邻域，取其带权重的平均值作为最后的灰度值。

2. 使用一阶有限差分计算梯度的幅值和方向：梯度表示灰度值变化的程度和方向，方法是通过点乘一个 Sobel 算子得到不同方向的梯度值
   $$
   \begin{align}
   x, y 方向的梯度 &： g_x(m, n), g_y(m, n)
   \\\\梯度的值 &： G(m, n) = \sqrt{g_x^2 + g_y^2}
   \\\\梯度方向 &： \theta = arctan \frac{g_y}{g_x}
\end{align}
   $$
   
3. 非极大值抑制：高斯滤波有可能放大了边缘，通过过滤非最大值来使边缘宽度尽可能为1像素。看下面这张图：

   ![图源：Justin Liang](https://live.staticflickr.com/65535/33960532348_ee4332fba0_n.jpg)

   从像素 q 的地图方向查找，若 q 的梯度值同时大于 p 和 r 的梯度值，则认为 q 是极大值，将其作为边缘上的像素点。反之不是极大值，将 q 的灰度值置为 0 。

4. 使用双阈值检测算法检测和连接边缘：设置高低两个阈值 th1 和 th2 ，通常采用：
   $$
   the = 0.4th1
   $$

   1. 当像素梯度值大于 th1 时，认为该像素在一条强边缘上；
   2. 当像素梯度值小于 th2 时，认为该像素是噪声，将灰度值置 0 ；
   3. 当像素梯度值大于 th2 且小于 th1 时，认为该像素在一条弱边缘上，准备下一步的连接；
   4. 连接：从一条强边缘开始，若能找到一条与之相连的弱边缘，则将该弱边缘也视作边缘，否则将灰度值置为 0 。

   重复以上步骤，完成边缘的检测与连接。

### Scale-invariant Feature Transform

这个我当时理解起来也比较费劲，先总结一下步骤有一个大体的思路：

1. 生成 DOG 金字塔用来构建（近似）尺度空间；
2. 空间极值点检测，初步探查关键点；
3. 稳定关键点的精确定位；
4. 稳定关键点的方向信息分配；
5. 关键点描述；
6. 特征点匹配。

下面来一一说明。

#### 构建尺度空间

首先理解什么是图像金字塔，基本就是一个图像不断下采样降低分辨率和尺寸的过程，从小到大生成一个类似金字塔的结构，这里就不再详细说明。

关于高斯金字塔和拉普拉斯金字塔 LoG 这里也不作详细说明，因为不是我们关注的重点（虽然理解很重要），补充内容请看 [高斯金字塔与拉普拉斯金字塔](<https://zhuanlan.zhihu.com/p/32815143>) 。

这里的一个重点是 LoG 被证明了有真正的尺度不变性，SIFT 的作者 Lowe 在构建尺度空间时使用了高斯差分金字塔 DoG 来近似 LoG 算子，用于在尺度空间检测关键点。看下面这张图：

![图源：https://sensblogs.wordpress.com](https://live.staticflickr.com/65535/32894172277_07a195ac9b_z.jpg)

构建 DoG 的过程：

1. 对图像作不同程度的高斯模糊；
2. 对图像降采样。
3. 高斯金字塔中同一组图片作差分得到 DoG ；

即每一层的多个图片尺寸一样，平滑系数不同，同一尺度下一组图片的模糊程度逐渐变大。

#### 初步探查关键点

寻找 DoG 金字塔中的极值点，要和每个像素点周围所有相邻的点做比较，如图：

![图源：Opencv](https://live.staticflickr.com/65535/47838189761_01afdab438_o.jpg)

1. 同一图片内该像素和周围 3x3 邻域内的 8 个像素点比较；
2. 在同一组图片内，该点和上下相邻两层图像的 2x9 个像素点比较。

这两步可以保证关键点在尺度空间和二维图像空间都是局部极值点（2x9+8=26）。

#### 精确匹配稳定的关键点

上面的到的极值点是离散空间的极值点，为了提高关键点的稳定性，需要对 DoG 函数进行曲线拟合，去除不稳定的极值点和错误检测出的极值点。这步的目的是增强匹配的稳定性，提高抗噪声的能力。

稳定的极值点是在不同尺度下提取的，保证了关键点的尺度不变性，即缩放不影响关键点。

#### 稳定关键点的方向信息分配

为关键点分配方向信息，是要保证对图像角度变化和旋转的不变性。

方向的分配通过求每个极值点的梯度实现。
$$
\begin{align}
梯度幅值&：m(x, y) = \sqrt{[L(x+1, y) - L(x-1, y)]^2 + [L(x, y+1) - L(x, y-1)]^2}
\\\\ 梯度方向&：\theta(x, y) = arctan \frac{L(x, y+1) - L(x, y-1)}{L(x+1, y) - L(x-1, y)}
\end{align}
$$
但是，分配给关键点的方向并不直接使用关键点的梯度方向，而是计算以关键点为中心的邻域内所有点的梯度方向，并归一化到 36 个方向内（每个方向 10 度），统计落在每个方向内的点的个数，生成一个梯度直方图，并进行以下步骤：

1. 直方图内纵坐标最大的方向作为关键点的主方向；
2. 相当于主峰值的 80% 的峰值的方向作为关键点的辅方向。

这样便为每个关键点分配了方向信息。

#### 关键点描述

描述是实现下一步关键点匹配的关键步骤，对关键点的描述不仅应包含关键点的信息，而且也应包含关键点周围对其有贡献的邻域点。思路和上一步有些像，看下面这张图：

![图源：Zeynep Akata](https://live.staticflickr.com/65535/33961228178_76292310b2_z.jpg)

这张图片可以这样理解：对关键点周围的像素区域分块，计算块内的梯度方向直方图，这个直方图从 36 个方向归一化到了 8 个方向，从而生成了一个独特的向量来描述该区域的图像信息。图片中将关键点周围信息分成了 2x2 的块来描述该区域信息，每个块内是 4x4 的像素区域，方向归一化到了 8 个。

Lowe 的实验表明，当采用 4x4 的块，8 个方向信息描述关键点时效果最佳，此时向量长度为 4x4x8=128 。

#### 关键点匹配

最后就是匹配两张图片内的关键点。匹配通过计算两组关键点的特征描述符（128维向量）欧氏距离来实现。距离越小，相似度越高。为其设置一个阈值，当距离小于这个阈值时认为两个关键点匹配成功。

上面便是我个人总结的传统计算机视觉领域的三大特征提取算法的基本步骤，由于本人水平非常有限，说的也比较简洁直白，不足之处请多包涵。

