---
title: "TopK问题以及在海量数据下的情况"
date: 2020-03-11T19:07:14+08:00
Description: ""
Tags: []
Categories: []

---

解释：简单来说就是在一堆数据里面找到前 K 大（当然也可以是前 K 小）的数。

### 一般做法

1. 排序，快排，然后取对应下标一侧的数据。数据量大时排序慢，而且不一定需要排序所有的。

2. 改进版，冒泡，只需要冒前K个，将全局排序优化为局部排序，但是仍需要排序。

3. 快排的另一种转换思路：如果一次排序的中间值等于K（类似寻找统计学中位数的问题），一侧就是TopK的数据。如果不等于只需要在一侧递归寻找即可。缺点是需要将数据一次载入内存，并且需要修改数组内容。

```
上面的方法也叫“随机选择”。注意，这种方法是经典的“减治法”，和分治法不同的是减治法只需要求解一个子问题便可解决大问题，分治法需要解决所有的小问题才可以解决大问题。因此减治法时间复杂度是O(logn)，分治法则是O(nlogn)；

分治法，大问题分解为小问题，小问题都要递归各个分支，例如：快速排序
减治法，大问题分解为小问题，小问题只要递归一个分支，例如：二分查找，随机选择
```

4. 经典解法：若找TopK大，维护一个大小为K的小顶堆，依次将数据放入堆中，当堆的大小满了的时候，只需要将堆顶元素与下一个数比较：如果大于堆顶元素，则将当前的堆顶元素抛弃，并将该元素插入堆中，**调整堆（这一步带来开销）**。遍历完全部数据，Top K 的元素也自然都在堆里面了。这种方式同样适合海量数据，不需要将数据一次加载完毕，可以一次只取一部分，因为我们只需要将数据一个个拿来与堆顶比较。时间复杂度是：遍历全部数据是O(n)，每次和堆顶比较若**产生调整**则为O(logk)，共O(nlogk)。当k足够小，可视作O(n)。建堆时间复杂度为O(k)，可视作常数，注意建堆时间不是O(klogk)，因为是自底向上，具体可看[推导](https://blog.csdn.net/LeoSha/article/details/46116959)。

### 海量数据处理

1. 分布式思想：将数据分散在多台机器中，然后每台机器并行计算各自的 TopK 数据，最后汇总，再计算得到最终的 TopK 数据。

2. 40亿个数，查找某个数字是不是在里面。所需内存
```
40 * 10 ^ 8 * 4B(int大小) = 16G
```

方法一：bitmap，当然可以同时使用布隆过滤器；

方法二：将这么多的数据分成许多块， 比如每一个块的大小是1000，那么第一块保存的就是0到999的数，第2块保存的就是1000 到1999的数……实际上我们并不保存这些数，而是给每一个块设置一个计数器。 这样每读入一个数，我们就在它所在的块对应的计数器加1。处理结束之后， 我们找到一个块，它的计数器值小于块大小(1000)， 说明了这一段里面一定有数字是文件中所不包含的。然后我们单独处理这个块即可。

### TopK终极思路

特定的统计方式+堆，统计方式主要是hashmap，对单词的话可以采用Trie树。然后再维护一个大小为K的小顶堆。